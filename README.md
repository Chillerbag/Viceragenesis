# Project 2 Report

Read the [project 2
specification](https://github.com/feit-comp30019/project-2-specification) for
details on what needs to be covered here. You may modify this template as you see fit, but please
keep the same general structure and headings.

Remember that you must also continue to maintain the Game Design Document (GDD)
in the `GDD.md` file (as discussed in the specification). We've provided a
placeholder for it [here](GDD.md).

## Table of Contents

- [Evaluation Plan](#evaluation-plan)
- [Evaluation Report](#evaluation-report)
- [Shaders and Special Effects](#shaders-and-special-effects)
- [Summary of Contributions](#summary-of-contributions)
- [References and External Resources](#references-and-external-resources)

## Evaluation Plan

# Evaluation Techniques
### 1. Observation Hybrid: Cooperative Evaluation - Post-Task Walkthrough

We have decided to utilize a hybrid of two observational techniques taught in class to leverage each technique's benefits. To avoid overlooking insights due to overwhelming tasks, observations will be limited to "levels" and short experiences at a time. 

For each individual, we will ask them to comment on any aspects of the game that they like or don't like during the walkthrough, rather than asking them to walk us through how they play the game. This attempts to reduce the "think aloud" awkwardness that can occur when one has to dictate their actions, simultaneously trying to avoid the awkward silences that can occur with the "cooperative evaluation" technique. Additionally, by opening the conversation up during gameplay, we can record insights and details that occur in real time without risking them being forgotten, which can occur with the "post-task walkthrough" technique. 

We aim to reduce the overhead the user faces while playing the game by recording the general "what", "why", "what next?" thought process from our own observations rather than dictation directly from the user, and limiting our questioning of those observations to points of confusion or anomalies. By asking the user to comment on emotions they feel and their likes and dislikes during the gameplay, we can record those comments and then utilize an informed "post-walkthrough" approach. Prior to the evaluation, we will have a prepared set of questions that can be adapted to user's comments to gain greater insights. A few adaptable questions for example:

* You mentioned [ aspect of game ] was [ visual description ]. What specifically made it [ unappealing or appealing]?
* What emotions did you feel during the gameplay? 
* Why was [ experience in game ] frustrating?
* What influenced that decision for you?
* At any point did your mind wander? [when, (if so) were you bored?]

Though there is the risk of experimenter bias influencing observations, we believe the trade-off with the insights we can obtain from our observation strategy has greater benefit.


### 2. Query Techniques
#### 2.1 Interviews
As mentioned above, we plan to conduct post-walkthrough interviews. By interviewing the users with adaptable questions, we hope to create an interview that is semi-structured. The structured aspect of the interview will help us ensure we ask crucial questions, and the adaptable aspect of the interview allows us to deviate for insight. 

Here is an example semi-structured interview.

#### 2.2 Scalar Questionnaire
To end the experiment, we plan to ask the user to fill out a quick anonymous usability questionnaire, based on post-study questionnaires for User Interaction Satisfaction (Brooke 1996). This aims to uncover any usability or frustrations that the user may have encountered but either felt too awkward to express (hence the anonymity), or too abstract to articulate in an interview format. Additionally, the scalar nature of the questionnaire will provide us an easy metric for analysis of our game, a good foundation for evaluating the user experience.  

Here is our planned usability questionnaire.

Brooke, J. (1996). SUS: A “quick and dirty” usability scale. Usability Evaluation In Industry, 207–212. [doi 10.1201 9781498710411 35](https://doi.org/10.1201/9781498710411-35).

## Evaluation Report

TODO (due milestone 3) - see specification for details

## Shaders and Special Effects

TODO (due milestone 3) - see specification for details

## Summary of Contributions

TODO (due milestone 3) - see specification for details

## References and External Resources

TODO (to be continuously updated) - see specification for details
